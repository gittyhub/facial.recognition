{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "The objective is to use detect and recognize faces using the face_recognition, and opencv package. We will use face_recogniton package to load and compre faces, and opencv will be use with our webcam to identify faces per frame. The majority of this walk through was gathered from different articles and videos that will be linked below. Although I didnt go through the OpenCV documentations, this was a good start and at some point I would like to do a complete OpenCV walk through. It was recomended to use a virtual environment however for simplicy I will only touch on how to set one up.\n",
    "\n",
    "This tutorial will be broken down in many parts listed below:\n",
    "\n",
    "0. [Virtual Environment](#0.-Setting-up-Virtual-Enviromentent)\n",
    "1. [Finding Face](#1.Finding-Face)\n",
    "2. [Face Matching](#2.Face-Matching)\n",
    "3. [Pulling Faces](#3.Pulling-Faces)\n",
    "4. [Identifing Faces](#4.Identifing-Faces)\n",
    "5. [Facial Dectection in Video](#5.Facial-Dectection-in-Video)\n",
    "\n",
    "\n",
    "Follow up:\n",
    " - From command line, show the face distance and adjust tolerance, @4:30 of youtube video\n",
    " - Go through OpenCV doc\n",
    " - Try same setup with usb camera to better capture training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Setting up Virtual Enviromentent\n",
    "[Top](#Objective)\n",
    "<br>\n",
    "<br>\n",
    "There is something to be had about virtual environmentments. When I first started this project, they idea was to install OpvenCV and get right to work. The reality is there were a few depenet packages along the way and I really forgot what they all were. If I were to try to replicate this again I wouldnt know which package or version I had installed, and some of the commands wouldnt work correctly. This step can save you hours worth of time in the future.\n",
    "\n",
    "Check Version\n",
    "<br>\n",
    "`python --version`\n",
    "<br>\n",
    "`pip --version`\n",
    "<br>\n",
    "<br>\n",
    "Install Pipenv\n",
    "<br>\n",
    "`pip3 install virtualenv`\n",
    "<br>\n",
    "<br>\n",
    "Upgrade if needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virtual Environment\n",
    "Typically you would \n",
    "1) Create a virtual enviromentment folder to house all your virtual environment, AllVirtualEnv\n",
    "<br>\n",
    "2) Create a folder in housed folder for your project, /AllVirtualEnv/Project.File\n",
    "<br>\n",
    "3) Go to the bin of the project file\n",
    "<br>\n",
    "4) Activate the new environment\n",
    "<br>\n",
    "5) Deactivate when done\n",
    "<br>\n",
    "1) `mkdir AllVirtualEnv`\n",
    "<br>\n",
    "2) `mkdir /AllVirtualEnv/Project.File`\n",
    "<br>\n",
    "3) `cd /AllVirtualEnv/Project.File/bin`\n",
    "<br>\n",
    "4) `source activate`\n",
    "<br>\n",
    "5) `deactivate`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Finding Face\n",
    "[Top](#Objective)\n",
    "<br>\n",
    "<br>\n",
    "The first exercise is find faces in a picture. To achive this we download the 'face_recognition' package.\n",
    "<br>\n",
    "`pip3 install face_recognition`\n",
    "<br>\n",
    "and execute the following code\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locations of faces are at \n",
      "[(163, 211, 271, 103), (255, 354, 345, 265), (96, 827, 225, 698), (275, 673, 365, 583), (305, 474, 395, 384)]\n",
      "Number of faces in photo, 5\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "\n",
    "image = face_recognition.load_image_file('./unknown/alison.brie.community.cast.png') #load image as numpy arrary\n",
    "face_location = face_recognition.face_locations(image) #Array of coordinates of each face\n",
    "print('Locations of faces are at \\n' + str(face_location))\n",
    "print(f'Number of faces in photo, {len(face_location)}') #Simple count of the array to count how many people\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code output above is pretty simple. We load the face_recognition package, find the location of the all faces in a picture that we pass using the .face_location function. The function returns a tuple of the location of the square boxes around each person's face,  (top, right, bottom, left). There are 5 faces so five items in our tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Face Matching\n",
    "[Top](#Objective)\n",
    "<br>\n",
    "<br>\n",
    "Lets see if we can match two face to see if they are the same person. I alway mix up Jamie Pressly and Margo Robbie, they could be sisters if you as me, so lest see if our progam is smart enough to see the different.\n",
    "<br>\n",
    "We load the first image we want to compare, Jamie Pressly, then we us the .face_encoding() to get a 128-dimensional face encoding for each face in the image. We do the same for Margo Robbie and use the .compare_faces to see if the program can tell the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The faces do not match\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "\n",
    "image_of_jpressly = face_recognition.load_image_file('/home/hman/Documents/virtualenvs/openCV/known/j.pressly.jpg')\n",
    "\n",
    "#Face encoding to get facial feature to compare faces\n",
    "kate_face_encoding = face_recognition.face_encodings(image_of_jpressly)[0] #taking only the first array\n",
    "\n",
    "#image to copare it to\n",
    "unknown_image = face_recognition.load_image_file('/home/hman/Documents/virtualenvs/openCV/unknown/m.robbie.unknown.jpg')\n",
    "unknown_face_encoding = face_recognition.face_encodings(unknown_image)[0] #taking only the first array\n",
    "\n",
    "#Compare images\n",
    "results = face_recognition.compare_faces([kate_face_encoding],unknown_face_encoding) #For the first argument you can use a list\n",
    "\n",
    "if results[0]:\n",
    "  print('The faces are a match')\n",
    "else:\n",
    "  print('The faces do not match')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The program is better at distingusing faces than I am"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Pulling Faces\n",
    "[Top](#Objective)\n",
    "<br>\n",
    "<br>\n",
    "Here we will load the same file of the Community cast using the .load_image_file from the face_recognition package. Get the face location of all the faces and use the Image function from the PIL package to extract the faces from the image into separate files, 5 faces, 5 image fiel for each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import face_recognition\n",
    "\n",
    "image = face_recognition.load_image_file('./unknown/alison.brie.community.cast.png')\n",
    "face_locations = face_recognition.face_locations(image) #this finds the location of the faces, return an arrary for (top, right, bottom, left)\n",
    "\n",
    "for face in face_locations:\n",
    "  top,right, bottom, left = face #Here we assign the four attributes to their respectful variables location\n",
    "  face_image = image[top:bottom, left:right] #then we take the image that we loaded and appply the variable attributes above to get the image of the face\n",
    "  pil_image = Image.fromarray(face_image) #then the PIL function takes the values from the array to cut the faces out \n",
    "  #pil_image.show()\n",
    "  pil_image.save(f'{top}.png') #saving the file using the location of the top variable as the file name\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done you should have 5 .png files with each of the faces from the image you loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.Identifing Faces\n",
    "[Top](#Objective)\n",
    "<br>\n",
    "<br>\n",
    "Next we are going to try to draw boxes around the faces of the people from the Community cast. This works very much like the last we codes we ran:\n",
    "<br>\n",
    "1) Load image file of known face (Alison Brie)\n",
    "<br>\n",
    "2) Encode the face to get a list of 128-dimensional face encodings\n",
    "<br>\n",
    "3) Assign the face encoding names\n",
    "<br>\n",
    "4) Load image file of unknown face to test (Community Cast)\n",
    "<br>\n",
    "5) Get face location for the unknown face using face_recognition.face_locations()\n",
    "<br>\n",
    "6) Encode the unknown faces using the location from #5 with .face_encoding()\n",
    "<br>\n",
    "7) Use PILLOW to create the unknown face to a PILLOW format\n",
    "<br>\n",
    "8) Create draw instance so we can draw boxes around the unknonw faces\n",
    "<br>\n",
    "9) Draw square around the face, then small square underneath, then label inside of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99205385 0.89515966]\n",
      "[0.48802559 0.75429731]\n",
      "[0.96776413 0.93438534]\n",
      "[0.79075103 0.50995554]\n",
      "[0.92704192 0.99004671]\n"
     ]
    }
   ],
   "source": [
    "import face_recognition\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "#Identify faces and draw a box around known faces\n",
    "#Unknown around unknown faces\n",
    "#https://www.youtube.com/watch?v=QSTnwsZj2yc\n",
    "\n",
    "image_of_alison = face_recognition.load_image_file('./known/alison.brie.jpg') #load image as numpy arrary\n",
    "alison_face_encoding = face_recognition.face_encodings(image_of_alison)[0] #taking only the first array\n",
    "\n",
    "image_of_gillian = face_recognition.load_image_file('./known/gillian.jacobs.jpg') #load image as numpy arrary\n",
    "gillian_face_encoding = face_recognition.face_encodings(image_of_gillian)[0] #taking only the first array\n",
    "\n",
    "#Create arry of encoding and names\n",
    "known_face_encodings = [gillian_face_encoding,alison_face_encoding]\n",
    "known_face_names = [\"Gillian.Jacobs\",\"Alison.Bri\"]\n",
    "\n",
    "\n",
    "#Load test image to find faces in\n",
    "test_image = face_recognition.load_image_file('./unknown/alison.brie.community.cast.png') #load image as numpy arrary\n",
    "\n",
    "#Find faces in test image\n",
    "face_locations = face_recognition.face_locations(test_image) #gets location of 5 faces unknown\n",
    "face_encodings = face_recognition.face_encodings(test_image, face_location) #encodes those 5 faces unknown\n",
    "#.face_encoding(face_img, known_face_location)\n",
    "\n",
    "#Convert image to PIL format\n",
    "pil_image = Image.fromarray(test_image) #Create a PILLOW immage to memory\n",
    "\n",
    "#Create a ImageDraw instance\n",
    "draw = ImageDraw.Draw(pil_image) #Makes it possile to draw on the image, our square boxes around each face\n",
    "\n",
    "#Loop through faces in test image\n",
    "for(top, right, bottom, left), face_encoding in zip(face_locations, face_encodings): #assign (top, right, bottom, left) and face encoding to the zip of face_locationS and face_encodingS\n",
    "  matches = face_recognition.compare_faces(known_face_encodings, face_encoding) #returns list, compares known face of Alison Brie to face_encoding no 's' above\n",
    "  #print(face_recognition.face_distance(known_face_encodings, face_encoding))   #how its doing it is that its taking the first face then see if it match the known_face list\n",
    "                                                        #so it takes the encoding for Abed and since it does match Gillian or Alison it returns [False, False]\n",
    "  name = \"Unknon Person\"\n",
    "  \n",
    "\n",
    "  #If match                                      #little tricky here\n",
    "  if True in matches:                            #if matches is true from the above face_recognition.compare_faces, that is it finds a match then\n",
    "    first_match_index = matches.index(True)      #gets the index of the true, so if Gillian was a match it would return [0], because in our list of known people its [Gillian, Alison]\n",
    "    name = known_face_names[first_match_index]   #indexs the name from known_faces_names from above index\n",
    "  #Draw the box, another small rectangle, then a name in the small rectangle\n",
    "  draw.rectangle(((left,top), (right,bottom)), outline=(0,0,0)) #outline is rbg color\n",
    "\n",
    "  #Draw label\n",
    "  tex_width, text_height = draw.textsize(name)\n",
    "  draw.rectangle(((left, bottom - text_height -10), (right, bottom)), fill=(0,0,0), outline=(0,0,0)) #rectangle name will be drawn on top of\n",
    "  draw.text((left + 6, bottom-text_height - 5), name, fill=(255,255,255,255)) #255 x4 means color white\n",
    "\n",
    "del draw\n",
    "\n",
    "pil_image.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.Facial Dectection in Video\n",
    "[Top](#Objective)\n",
    "<br>\n",
    "<br>\n",
    "Here we want to use video for facial recognition. Pretty much going to follow the same steps as we did for the still images, except this time we are going to apply it to video. This was done following the turorial below. Overall it worked, but didnt turn out the way I originally intended as noted above in the objective.\n",
    "<br>\n",
    "<br>\n",
    "0) Initialize video capture using cv2\n",
    "<br>\n",
    "1) Load image file of known (bruno)\n",
    "<br>\n",
    "2) Encode the face to get a list of 128-dimensional face encodings (bruno)\n",
    "<br>\n",
    "3) Assign the face encoding names (bruno)\n",
    "<br>\n",
    "4) Start a \"loop\" using while to capture all the frames from the camera\n",
    "<br>\n",
    "5) Get face location for the unknown face using face_recognition.face_locations()\n",
    "<br>\n",
    "6) Encode the unknown faces using the location from #5 with .face_encoding()\n",
    "<br>\n",
    "7) Create a for loop to iterate throught each video frame\n",
    "<br>\n",
    "8) Check to see if the face match\n",
    "<br>\n",
    "9) Set a rectangle around the face with name\n",
    "<br>\n",
    "https://www.youtube.com/watch?v=lC_y8wD7F3Y&t=797s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-627bf5972f3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvideo_capture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#takes the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mrgb_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#change the color for the frame to rbg color\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mface_locations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_locations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgb_frame\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#get the face location of the frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import face_recognition as fr\n",
    "import cv2\n",
    "\n",
    "#https://github.com/bertcenteno/face_recognition_video_tutorial/blob/master/face_reco_webcam.py\n",
    "\n",
    "video_capture = cv2.VideoCapture(0) #initialize video capture\n",
    "\n",
    "bert_image = fr.load_image_file(\"./known/hman.png\") #load known image\n",
    "bert_face_encoding = fr.face_encodings(bert_image)[0] #encode the first image\n",
    "\n",
    "known_face_encondings = [bert_face_encoding] #put the encoding in a list\n",
    "known_face_names = [\"hman\"] #identify the first encoding name, this will grow if you add more people, will be used in a zip later\n",
    "\n",
    "while True: \n",
    "    ret, frame = video_capture.read() #takes the frame\n",
    "\n",
    "    rgb_frame = frame[:, :, ::-1] #change the color for the frame to rbg color\n",
    "\n",
    "    face_locations = fr.face_locations(rgb_frame) #get the face location of the frame\n",
    "    face_encodings = fr.face_encodings(rgb_frame, face_locations) #take the frame, use the location to encode the face\n",
    "\n",
    "    for (top, right, bottom, left), face_encoding in zip(face_locations, face_encodings): #zip face location and face encoding.\n",
    "                                                                                            #assign t,r,b,l to face_location, and face_encodings to face encoding\n",
    "        matches = fr.compare_faces(known_face_encondings, face_encoding) #compare the two face from the known and frame\n",
    "        name = \"Unknown\"\n",
    "\n",
    "        face_distances = fr.face_distance(known_face_encondings, face_encoding)#similar to the compare_faces but here we get a % of how close face are to each other\n",
    "\n",
    "        best_match_index = np.argmin(face_distances) #Take the % from above in .face_distance and pick the smallest one. \n",
    "                                                        #compare_face is a binary T/F, face_distance give you a continouse output, the lower the better\n",
    "        if matches[best_match_index]: #not sure how this works as matches would return a [T/F] while best_match_index should return a %\n",
    "            name = known_face_names[best_match_index]\n",
    "        \n",
    "        cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), 2) #draw rectangles around the face in frame, using l,t and r,b\n",
    "\n",
    "        cv2.rectangle(frame, (left, bottom -35), (right, bottom), (0, 0, 255), cv2.FILLED) #second rectance under the face, with offset 35 dowm\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX #pick your font\n",
    "        cv2.putText(frame, name, (left + 6, bottom - 6), font, 1.0, (255, 255, 255), 1) #adds name to the rectange using your font\n",
    "\n",
    "    cv2.imshow('Webcam_facerecognition', frame) #show the image, window name will be Webcam..., could be any name you want. Then show the frame we drew rectangels on\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): #press q to quit\n",
    "        break\n",
    "\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
